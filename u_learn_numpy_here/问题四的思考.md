# 问题四的思考：

实际上就是这么个情况：

>如果你的眼睛看东西不准，你要怎么办？戴眼镜还是做激光？

我的传感器不准，所以在PF每次修改粒子权重的时候，修的弄巧成拙了。

实际上的PF整体没有问题。而且是如果要不是传感器不准，PF 的修正每个粒子的准确率更高。

问题出在PF算法外部，我们希望出现的这个问题，仍旧可以被当前的PF handle住。方法有二：

1）在算法外做：尽力减小传感器误差：我们通过一些方法让传感器数据，就是表征robot 和地标的真实距离数据。

2）在算法内做：我们知道有误差，我们修改算法的某处，令其能辨别，并消除误差。

## 方法一：

如果robot 是匀速运动，那么把传感器的数据每次记录下来，数据之间的增量应该是定值，say：incVal
，后期每次得到一个新的距离数据，立刻减去上一个时刻的，得到本次增量，say: incVar, then:

`realMoveInc = incVar + ratio * (incVar - incVal)`

或者使用TCP round trip time 类似的自适应调整算法。因为每次增量应该相差不大（给定一个稳定的速度），so we have something like:

    this_time_inc_val = (q * last_time_inc_val) + ((1 - q) * this_time_sensor_inc_var)// 0 < q < 1

上式中，q代表你多相信之前的一次数据

## 方法二：

不知道
